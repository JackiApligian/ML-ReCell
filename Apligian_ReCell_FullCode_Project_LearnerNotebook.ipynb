{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackiApligian/ML-ReCell/blob/main/Apligian_ReCell_FullCode_Project_LearnerNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2r5o8SR4rqH"
      },
      "source": [
        "# Supervised Learning - Foundations Project: ReCell "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SntBY974rqJ"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA_GXJwuhmVz"
      },
      "source": [
        "### Business Context\n",
        "\n",
        "Buying and selling used phones and tablets used to be something that happened on a handful of online marketplace sites. But the used and refurbished device market has grown considerably over the past decade, and a new IDC (International Data Corporation) forecast predicts that the used phone market would be worth \\\\$52.7bn by 2023 with a compound annual growth rate (CAGR) of 13.6% from 2018 to 2023. This growth can be attributed to an uptick in demand for used phones and tablets that offer considerable savings compared with new models.\n",
        "\n",
        "Refurbished and used devices continue to provide cost-effective alternatives to both consumers and businesses that are looking to save money when purchasing one. There are plenty of other benefits associated with the used device market. Used and refurbished devices can be sold with warranties and can also be insured with proof of purchase. Third-party vendors/platforms, such as Verizon, Amazon, etc., provide attractive offers to customers for refurbished devices. Maximizing the longevity of devices through second-hand trade also reduces their environmental impact and helps in recycling and reducing waste. The impact of the COVID-19 outbreak may further boost this segment as consumers cut back on discretionary spending and buy phones and tablets only for immediate needs.\n",
        "\n",
        " \n",
        "### Objective\n",
        "\n",
        "The rising potential of this comparatively under-the-radar market fuels the need for an ML-based solution to develop a dynamic pricing strategy for used and refurbished devices. ReCell, a startup aiming to tap the potential in this market, has hired you as a data scientist. They want you to analyze the data provided and build a linear regression model to predict the price of a used phone/tablet and identify factors that significantly influence it.\n",
        "\n",
        " \n",
        "### Data Description\n",
        "\n",
        "The data contains the different attributes of used/refurbished phones and tablets. The data was collected in the year 2021. The detailed data dictionary is given below.\n",
        "\n",
        "\n",
        "- brand_name: Name of manufacturing brand\n",
        "- os: OS on which the device runs\n",
        "- screen_size: Size of the screen in cm\n",
        "- 4g: Whether 4G is available or not\n",
        "- 5g: Whether 5G is available or not\n",
        "- main_camera_mp: Resolution of the rear camera in megapixels\n",
        "- selfie_camera_mp: Resolution of the front camera in megapixels\n",
        "- int_memory: Amount of internal memory (ROM) in GB\n",
        "- ram: Amount of RAM in GB\n",
        "- battery: Energy capacity of the device battery in mAh\n",
        "- weight: Weight of the device in grams\n",
        "- release_year: Year when the device model was released\n",
        "- days_used: Number of days the used/refurbished device has been used\n",
        "- normalized_new_price: Normalized price of a new device of the same model in euros\n",
        "- normalized_used_price: Normalized price of the used/refurbished device in euros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_-uuGqH-qTt"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeF8YaNKDPyK"
      },
      "outputs": [],
      "source": [
        "#Importing all necessary libraries for data manipulation and visalization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "\n",
        "#Importing libraries for data analysis and stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxhpZv9y-qTw"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJwX9wuc4rqL"
      },
      "outputs": [],
      "source": [
        "#mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#loading dataset from drive\n",
        "data=pd.read_csv('/content/drive/My Drive/used_device_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvpMDcaaMKtI"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Observations\n",
        "- Sanity checks"
      ],
      "metadata": {
        "id": "tIiCRwqZ54_C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01hJQ7EfMKtK"
      },
      "outputs": [],
      "source": [
        "#checking the first few rows of the dataset\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the last few rows of the dataset\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "pMxeGPNwyofE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the shape of the dataset\n",
        "data.shape"
      ],
      "metadata": {
        "id": "eCtpmIzzyWiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are 3454 rows of data and 15 columns**"
      ],
      "metadata": {
        "id": "E2IjyjtLyhxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the dtypes of the data\n",
        "data.info()"
      ],
      "metadata": {
        "id": "Mb0etKTJyARY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are missing values in this data frame that will need to be addressed.**"
      ],
      "metadata": {
        "id": "fTiOY4buy6DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #Checking the value counts for the release year\n",
        "  data.value_counts('release_year')"
      ],
      "metadata": {
        "id": "lkkD_8Hj1k6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple years are included in this data frame. I will need to decide how to format as we look further into the data.**"
      ],
      "metadata": {
        "id": "TvQvDVNAytzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking at the statistical summary of the data\n",
        "data.describe(include='all').T"
      ],
      "metadata": {
        "id": "UuYazYIY3qla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are 34 unique brands in this data, with 4 unique operating systems. The average screen size is 13.7, there are more phones with 4g than 5g capabilities, the average release year is 2015 and average days used is 674.86 days.**"
      ],
      "metadata": {
        "id": "YALKgCGX3-Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for duplicated data\n",
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "9K3ohFRM66N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are no duplicated values.**"
      ],
      "metadata": {
        "id": "CyFlGx456-Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the df for missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "eJd98fDe7guL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are quite a few missing value with the majority in the main_camera_mp column.**"
      ],
      "metadata": {
        "id": "A_dVM3KT7qLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making a copy of the original dataframe so that it remains unchanged\n",
        "df=data.copy()"
      ],
      "metadata": {
        "id": "25UkOE848ApX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__7ciGcIDPyk"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- EDA is an important part of any project involving data.\n",
        "- It is important to investigate and understand the data better before building a model with it.\n",
        "- A few questions have been mentioned below which will help you approach the analysis in the right manner and generate insights from the data.\n",
        "- A thorough analysis of the data, in addition to the questions mentioned below, should be done."
      ],
      "metadata": {
        "id": "3bGVKmh75ri8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEyqzdJBb0jU"
      },
      "source": [
        "**Questions**:\n",
        "\n",
        "1. What does the distribution of normalized used device prices look like?\n",
        "2. What percentage of the used device market is dominated by Android devices?\n",
        "3. The amount of RAM is important for the smooth functioning of a device. How does the amount of RAM vary with the brand?\n",
        "4. A large battery often increases a device's weight, making it feel uncomfortable in the hands. How does the weight vary for phones and tablets offering large batteries (more than 4500 mAh)?\n",
        "5. Bigger screens are desirable for entertainment purposes as they offer a better viewing experience. How many phones and tablets are available across different brands with a screen size larger than 6 inches?\n",
        "6. A lot of devices nowadays offer great selfie cameras, allowing us to capture our favorite moments with loved ones. What is the distribution of devices offering greater than 8MP selfie cameras across brands?\n",
        "7. Which attributes are highly correlated with the normalized price of a used device?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN1lyueHttwW"
      },
      "outputs": [],
      "source": [
        "#funtion to create EDA with boxplot and histogram plots on the same scale\n",
        "def histogram_boxplot(data,feature,figsize=(15,10),kde=False, bins=None):\n",
        "  \"\"\"\n",
        "  Boxplot and histogram combined\n",
        "\n",
        "  data:dataframe\n",
        "  feature:dataframe column\n",
        "  figsize: size of the figure (default(15,10))\n",
        "  kde: whether to show the density curve (default False)\n",
        "  bins: number of bins for histogram (default None)\n",
        "  \"\"\"\n",
        "  #creating the 2 subplots\n",
        "  f2, (ax_box2, ax_hist2) = plt.subplots(nrows=2,#number of rows in the subplot grid = 2\n",
        "      sharex=True,#x-axis to be shared on all subplots\n",
        "      gridspec_kw={'height_ratios': (.25,.75)},\n",
        "      figsize=figsize, )\n",
        " \n",
        "  #boxplot will be created with a triangle showing the mean value of a column\n",
        "  sns.boxplot (data=data, x=feature, ax=ax_box2, showmeans=True, color= 'violet')\n",
        "  \n",
        "  # for histograms\n",
        "  sns.histplot(data=data,x=feature,kde=kde,ax=ax_hist2, bins=bins)if bins else sns.histplot(data=data, x=feature, kde=kde, ax=ax_hist2)\n",
        "    \n",
        "     #add means to histograms\n",
        "  ax_hist2.axvline(data[feature].mean(),color='green', linestyle='--')\n",
        "    \n",
        "    #adding median to histograms\n",
        "  ax_hist2.axvline(data[feature].median(), color='black', linestyle='-')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "# length of the column\n",
        "    total = len(data[feature])  \n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 2, 6))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 2, 6))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n],\n",
        "    )\n",
        "# percentage of each class of the category\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  \n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "# width of the plot\n",
        "        x = p.get_x() + p.get_width() / 2  \n",
        "# height of the plot\n",
        "        y = p.get_height()  \n",
        " # annotate the percentage\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        ) \n",
        "# show the plot\n",
        "    plt.show()  "
      ],
      "metadata": {
        "id": "LdowB_NMFMrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNIVARIATE ANALYSIS**"
      ],
      "metadata": {
        "id": "PWJDgmSRRLOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of normalized used price\n",
        "histogram_boxplot(data, \"normalized_used_price\")"
      ],
      "metadata": {
        "id": "eveNH2axGBhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What does the distribution of normalized used device prices look like?\n",
        "**The normalized used price has a slight left skew but with a normal distribution curve. The average price for a used phone is slightly less than 4.5 with 250 phones at that price. The boxplot shows that there are far more ouliers in the lower price range than the upper. The mean and median are close to the same amount.**"
      ],
      "metadata": {
        "id": "-aEd-R9_Ggs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of normalized new price\n",
        "histogram_boxplot(data,\"normalized_new_price\")"
      ],
      "metadata": {
        "id": "qUZyNK0sHiIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The normalized new price data follows the pattern of normalized distribution but has far more dips in the pattern compared to the used price distribution. The average price is around 5.2 but the majority of phones are priced at 5. The mean and median are close to the same amount.** "
      ],
      "metadata": {
        "id": "xReHMEUBH02O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of screen size\n",
        "histogram_boxplot(data, \"screen_size\")"
      ],
      "metadata": {
        "id": "AOXVvD58IxT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Screen size appears to have a relatively flat distribution except for the median amount that is around 13. The median and mean are slightly seperated.**"
      ],
      "metadata": {
        "id": "foYh-tx_JYUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of main camera mp\n",
        "histogram_boxplot(data,'main_camera_mp')"
      ],
      "metadata": {
        "id": "cLFNeUsGJvgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There is a right skewed distribution that is not normalized. The mean and median are slightly seperated and the mode is removed from them both.**"
      ],
      "metadata": {
        "id": "-hGpoK4eKBS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of selfie camera mp\n",
        "histogram_boxplot(data,'selfie_camera_mp')"
      ],
      "metadata": {
        "id": "CG-or7OXKzl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The selfie camera mp data is right skewed with many outliers to the higher end of the megapixel count. The median and mean are seperated and the data is not normalized.**"
      ],
      "metadata": {
        "id": "PIYQZZolLDCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of internal memory\n",
        "histogram_boxplot(data, 'int_memory')"
      ],
      "metadata": {
        "id": "BMu_9J_vLR-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The internal memory data is heavily skewed to the right with the median and mean seperated and the mode less than the median and mean. There is a huge outlier amount to the higher end of the data for this variable.**"
      ],
      "metadata": {
        "id": "Uap5ZldGLdFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of ram\n",
        "histogram_boxplot(data, 'ram')"
      ],
      "metadata": {
        "id": "_TY0m4-6LsJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The ram data is right skewed with a relatively flat distribution except for the median and mean values of 4 ram. There is a large difference in the number of phones with 4 ram than any other amount. There are over 2500 phones in the data with 4 ram while the other ram amounts do not have more than 250 phones in the data.**"
      ],
      "metadata": {
        "id": "ZaLe-EUNL4r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of weight\n",
        "histogram_boxplot(data,'weight')"
      ],
      "metadata": {
        "id": "uz8qg3yAMPzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The weight of the phones in the data is heavily skewed to the right. The information of phones less than 200 is normalized followed by many phones weighing more than 200 in a relatively flat distribution pattern. The median and mode are seperated.**"
      ],
      "metadata": {
        "id": "Xk_Gx1fnMVfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of the battery\n",
        "histogram_boxplot(data, 'battery')"
      ],
      "metadata": {
        "id": "dQhTFQdtMsrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The battery data has a right skew with the meidan and mean lining up with the mode. The majority of battery are at the 2000, 3000 and 4000 values.**"
      ],
      "metadata": {
        "id": "Hm7fVENyM1GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of days used\n",
        "histogram_boxplot(data, \"days_used\")"
      ],
      "metadata": {
        "id": "V_fY7gR5NC5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The days used has a left skew with the mode being less than the seperated median and mean amounts.**"
      ],
      "metadata": {
        "id": "mS4JjnB-NOb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.value_counts('brand_name')"
      ],
      "metadata": {
        "id": "IExpWmpQN-af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#brand name distribution\n",
        "labeled_barplot(data,'brand_name', perc=True, n=33)"
      ],
      "metadata": {
        "id": "PlLU7ROMNbb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Most of the phones in the data frame are in the \"Others\" catagory with the next highest number being Samsung phones at 9.9%. The brand with the smallest number of phones in the data is Google at .4%.**"
      ],
      "metadata": {
        "id": "uDOBMPc9No0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of OS\n",
        "labeled_barplot(data,\"os\", perc=True, n=10)"
      ],
      "metadata": {
        "id": "mjOtYW7KOdgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What percentage of the used device market is dominated by Android devices?\n",
        "**The majority of phones have the Android operating system at 93.1%. The iOS has the least amount at 1.0%.**"
      ],
      "metadata": {
        "id": "8evbB-ubOx83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data,'4g', perc=True, n=2 )"
      ],
      "metadata": {
        "id": "wrlB3HpSPKH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**67.6% of the phones in the dataframe have 4g capability and 32.4% do not.**"
      ],
      "metadata": {
        "id": "Onvb5nYqPWyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of 5g\n",
        "labeled_barplot(data,'5g', perc=True, n=2)"
      ],
      "metadata": {
        "id": "2fgakG-4PWSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**95.6% of the phones in the dataframe do not have 5g capabilities while 4.4% do.**"
      ],
      "metadata": {
        "id": "zbIdobvBP8yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(data,'release_year', perc=True, n=10)"
      ],
      "metadata": {
        "id": "hp4A26UuQGjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The majority of phones in this dataframe were released in 2014 at 18.6% and the least amount were from 2020 at 8%.**"
      ],
      "metadata": {
        "id": "mYm9pQHIQdwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BIVARIATE ANALYSIS**"
      ],
      "metadata": {
        "id": "rtX4tcc9RFMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for coorelations in the data\n",
        "cols_list = df.select_dtypes(include=np.number).columns.tolist()\n",
        "#Because release year is a time variable, it needs to be dropped\n",
        "cols_list.remove(\"release_year\")\n",
        "\n",
        "plt.figure(figsize=(20, 15))\n",
        "sns.heatmap(\n",
        "    df[cols_list].corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SPn_iGcpQvSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The battery and screen size as well as weight and screen size have high coorelation values. Weight and battery are also coorelated. There is little coorelation between days used and any of the other variables.** \n",
        "7.Which attributes are highly correlated with the normalized price of a used device?**The highest coorelation is with the normalized new price values. The features that seem to be the highest correlation to normalized used price would be the screen size, selfie camera mp, and battery.**"
      ],
      "metadata": {
        "id": "JvQ-Kc8DSlwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing the amount of RAM to the different devices\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"brand_name\", y=\"ram\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uZbq4A9VTQXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. The amount of RAM is important for the smooth functioning of a device. How does the amount of RAM vary with the brand? **There is a great deal of variance across devices. The device that appears to have the most consistly high levels of RAM would be OnePlus. The device that appears to have the most consistly low levels of RAM would be Celkon. There are outliers for high RAM for Huawei, Micromax, Oppo, Samsung and Xiaomi.**"
      ],
      "metadata": {
        "id": "XMWp4k0BUfVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing battery size across phones\n",
        "#breaking the heavier phones into a new df\n",
        "df_large_batt = df[df.battery > 4500]\n",
        "df_large_batt.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "ab8jC30FVlTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The new dataframe has 341 rows and 15 columns so there were 341 phones in our original data that weight over 4500.**"
      ],
      "metadata": {
        "id": "BiUHrGV4WAbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#barplot comparing brand name to weight\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data = df_large_batt, x='brand_name', y='weight')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zpPWkuy4WLoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.A large battery often increases a device's weight, making it feel uncomfortable in the hands. How does the weight vary for phones and tablets offering large batteries (more than 4500 mAh)? **There is a great deal of variance across the phones in weight. The heaviest is an outlier in the Others catagory followed by Samsung. The Lenovo has the highest mean weight of all of the phones.**"
      ],
      "metadata": {
        "id": "5aB0xN2iVlo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing screen size across phones\n",
        "#breaking the phones with a larger screen size into a seperate df\n",
        "df_large_screen = df[df.screen_size > 6 * 2.54]\n",
        "df_large_screen.shape"
      ],
      "metadata": {
        "id": "PIGCYb_vXnEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are now 1099 rows and 15 columns which means there were 1099 phones with larger screens in the original data frame.**"
      ],
      "metadata": {
        "id": "-Fb50p9PYFWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#barplot to compare screen size to brand name\n",
        "labeled_barplot(df_large_screen, 'brand_name')\n"
      ],
      "metadata": {
        "id": "yAncVvjqYOP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Bigger screens are desirable for entertainment purposes as they offer a better viewing experience. How many phones and tablets are available across different brands with a screen size larger than 6 inches? **The majority of larger screens are from Huawei at 149 with Samsung close behind at 119.**"
      ],
      "metadata": {
        "id": "2DH6Yy5pXnUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing selfie cameras across phones\n",
        "#breaking the phones with a greater than 8mp selfie camera into a seperate df\n",
        "df_selfie_camera = df[df.selfie_camera_mp > 8]\n",
        "df_selfie_camera.shape"
      ],
      "metadata": {
        "id": "ZIhyTlciZXOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are 655 rows and 15 columns in this new dataframe so there are 655 phones with a selfie camera with greater than 8 megapixels.**"
      ],
      "metadata": {
        "id": "jBji6gEAZvnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#barplot to compare selfie camera to brand\n",
        "labeled_barplot(df_selfie_camera, 'brand_name')"
      ],
      "metadata": {
        "id": "tVs2yj7lZ98m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.A lot of devices nowadays offer great selfie cameras, allowing us to capture our favorite moments with loved ones. What is the distribution of devices offering greater than 8MP selfie cameras across brands? **The most phones with over 8 megapixels selfie cameras are from Huawei, Vivo and Xiaomi. Samsung is also high on the list.**"
      ],
      "metadata": {
        "id": "PzAfK5s1ZW8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#doing the same analysis with the rear camera\n",
        "#breaking the phones with a greater than 14mp rear camera into a seperate df\n",
        "df_rear_camera = df[df.main_camera_mp > 14]\n",
        "df_rear_camera.shape"
      ],
      "metadata": {
        "id": "MGXnSgaiach0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are 261 rows and 15 columns in this dataframe. So there are 261 phones in the original dataset that have over 14 mp in the rear camera.**"
      ],
      "metadata": {
        "id": "jYM8pNOtadWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing rear camera mp across brands\n",
        "labeled_barplot(df_rear_camera, 'brand_name')"
      ],
      "metadata": {
        "id": "gF9rEFUabrfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Samsung has the most phones with over 14 megapixal rear cameras at 44, followed by Sony at 37 and Others at 36.**"
      ],
      "metadata": {
        "id": "UnRCzxOIb6ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing price of the used phones to year released\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.lineplot(data=data, y='normalized_used_price', x='release_year') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xxAkjWPZcGGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The price goes up as the phone release year increases. So the newer the phone the more it costs.**"
      ],
      "metadata": {
        "id": "KFaJgGTGdOGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparing price to 4g and 5g capabilities\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(121)\n",
        "sns.boxplot(data=df, x=\"4g\", y=\"normalized_used_price\")\n",
        "\n",
        "plt.subplot(122)\n",
        "sns.boxplot(data=df, x=\"5g\", y=\"normalized_used_price\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I1Mz1Gz1dWQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The average price of the phones with 4g OR 5g capabilities are higher than those without. The price for the phones with 4g and without 5g are very similar which makes me question if they are the same data points.**"
      ],
      "metadata": {
        "id": "C65lvvT5d1qf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVn5toJ7MKte"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Missing value treatment\n",
        "- Feature engineering (if needed)\n",
        "- Outlier detection and treatment (if needed)\n",
        "- Preparing data for modeling\n",
        "- Any other preprocessing steps (if needed)"
      ],
      "metadata": {
        "id": "YcceZiPd5vGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Kl5WrDyyfab3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fixing the missing values in internal memory and ram by using the median for the release year and brand name to fill the value.\n",
        "cols_impute = [\n",
        "    \"main_camera_mp\",\n",
        "    \"selfie_camera_mp\",\n",
        "    \"int_memory\",\n",
        "    \"ram\",\n",
        "    \"battery\",\n",
        "    \"weight\",\n",
        "]\n",
        "\n",
        "for col in cols_impute:\n",
        "    df[col] = df[col].fillna(\n",
        "        value=df.groupby(['release_year', 'brand_name'])[col].transform(\"median\")\n",
        "    )\n",
        "\n",
        "# checking for missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "WMRu3nyUg-AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The internal memory and RAM missing values have been replaced by the release year and brand name median for that data point.**"
      ],
      "metadata": {
        "id": "m4CpiR7TiaEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fixing the missing values in the main camera mp, selfie camera mp, battery and weight columns by using the average of the brand names for those values.\n",
        "cols_impute = [\n",
        "    \"main_camera_mp\",\n",
        "    \"selfie_camera_mp\",\n",
        "    \"battery\",\n",
        "    \"weight\",\n",
        "]\n",
        "\n",
        "for col in cols_impute:\n",
        "    df[col] = df[col].fillna(\n",
        "        value=df.groupby(['brand_name'])[col].transform(\"median\")\n",
        "    ) \n",
        "\n",
        "# checking for missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "1uAswOGMixhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**These changes took care of all but 10 null values in the main camera mp column.**\n"
      ],
      "metadata": {
        "id": "eFRUd91CiZ_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#changing remainging missing values in the main camera mp column to the median of the entire main camera mp column\n",
        "df[\"main_camera_mp\"] = df[\"main_camera_mp\"].fillna(df[\"main_camera_mp\"].median())\n",
        "# checking for missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "p8Yb_K0djS77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All null or missing values have been replaced.**"
      ],
      "metadata": {
        "id": "qX_ECVblkOvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Since release year is a time variable, it should be changed so that it can be analyzed. Changing from release year to years since release using 2021 as the start year.\n",
        "#dropping the release year column.\n",
        "df[\"years_since_release\"] = 2021 - df[\"release_year\"]\n",
        "df.drop(\"release_year\", axis=1, inplace=True)\n",
        "df[\"years_since_release\"].describe()"
      ],
      "metadata": {
        "id": "XNuQhYXPkk6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for outliers\n",
        "num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "for i, variable in enumerate(num_cols):\n",
        "    plt.subplot(4, 3, i + 1)\n",
        "    sns.boxplot(data=df, x=variable)\n",
        "    plt.tight_layout(pad=2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sR-3Zy0VlEeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are numerous outliers in this data set but no treatment is needed because they are accurate values.**"
      ],
      "metadata": {
        "id": "44XOiKy_mLbF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNzFis7eEaXj"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It is a good idea to explore the data once again after manipulating it."
      ],
      "metadata": {
        "id": "ZkYW8xGS5xdR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lcDTGi9EZ1M"
      },
      "outputs": [],
      "source": [
        "#distribution of main camera mp after changes\n",
        "histogram_boxplot(data,'main_camera_mp')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization shows little change from previous plot.**"
      ],
      "metadata": {
        "id": "dDB0uWA2m9Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of selfie camera mp after changes\n",
        "histogram_boxplot(data,'selfie_camera_mp')"
      ],
      "metadata": {
        "id": "PV2niyoonK_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization shows little change from previous plot.**:"
      ],
      "metadata": {
        "id": "Eml89JDQnOYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of the battery after changes\n",
        "histogram_boxplot(data, 'battery')"
      ],
      "metadata": {
        "id": "bekh5qntnZ7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization shows little change from previous plot.**"
      ],
      "metadata": {
        "id": "SJpxQxCFnOUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of weight after changes\n",
        "histogram_boxplot(data,'weight')"
      ],
      "metadata": {
        "id": "HVPdMm8pnl6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization shows little change from previous plot.**"
      ],
      "metadata": {
        "id": "6gcRSj-8n4bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#barplot comparing brand name to weight\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data = df_large_batt, x='brand_name', y='weight')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mZs17oFaoAzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization shows little change from previous plot.**\n",
        "\n",
        "**These finding with the reanalysed EDA show that the changes made to the missing values did not affect the overall data in a meaningful way. This is good news.**"
      ],
      "metadata": {
        "id": "fsiRWTI_oVSN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeUzI1OB4rqM"
      },
      "source": [
        "## Model Building - Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining independent and dependent variables\n",
        "# independent variables\n",
        "X = df.drop([\"normalized_used_price\"], axis=1)\n",
        "# dependent variable\n",
        "y = df[\"normalized_used_price\"]"
      ],
      "metadata": {
        "id": "buXHbd7ufo8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For this model, the Normalized Used Price will be the dependent variable.**"
      ],
      "metadata": {
        "id": "yrt4LxC7T4v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.head())\n",
        "print()\n",
        "print(y.head())"
      ],
      "metadata": {
        "id": "KEXokFPdf-wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding intercept to data\n",
        "X = sm.add_constant(X)"
      ],
      "metadata": {
        "id": "vYzgdlt9gVWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dummies for the object dtypes for calculations\n",
        "X = pd.get_dummies(X,\n",
        "    columns=X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist(),\n",
        "    drop_first=True)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "SKWFzSbElxjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spliting the data into 70% training and 30% testing  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ],
      "metadata": {
        "id": "fjjOdF_IrWQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.head())"
      ],
      "metadata": {
        "id": "-I1peMZKr2jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape[0])"
      ],
      "metadata": {
        "id": "soJzegU-sMzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are 2417 rows in the training data**"
      ],
      "metadata": {
        "id": "If-VtE8OsXdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.head())"
      ],
      "metadata": {
        "id": "xq-V1VEqr-QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape[0])"
      ],
      "metadata": {
        "id": "FGWYEvVcsdEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are 1037 rows in the testing data**"
      ],
      "metadata": {
        "id": "gFneM4eYsk5e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3e6gzxdMKti"
      },
      "outputs": [],
      "source": [
        "#fitting the OLS model on the training data\n",
        "olsmodel1 = sm.OLS(y_train,X_train)\n",
        "olsres= olsmodel1.fit()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the OLS summary\n",
        "print(olsres.summary())"
      ],
      "metadata": {
        "id": "YL1OKdIStLWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The adjusted R-Squared value is .842 which lets us know that this model reflect an 84% fit to the data which suggests it is a good model.**"
      ],
      "metadata": {
        "id": "4cZ0IdDfxEcY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvoU3F6oMKti"
      },
      "source": [
        "## Model Performance Check"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In order to accept our model as a good fit, we need more information. We do this by creating funtions that calculate the MAPE and adjust R2.**"
      ],
      "metadata": {
        "id": "aTF474_tx7rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function to find adjusted R-squared\n",
        "def adj_r2_score(predictors, targets, predictions):\n",
        "    r2 = r2_score(targets, predictions)\n",
        "    n = predictors.shape[0]\n",
        "    k = predictors.shape[1]\n",
        "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
        "\n",
        "\n",
        "# creating a function to find MAPE\n",
        "def mape_score(targets, predictions):\n",
        "    return np.mean(np.abs(targets - predictions) / targets) * 100\n",
        "\n",
        "\n",
        "# creating a function to find the different metrics to check performance of the regression model\n",
        "def model_performance_regression(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Creating a function to find the different metrics to check regression model performance\n",
        "\n",
        "    model: regressor\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "# creatin a model to predict using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "# to compute R-squared\n",
        "    r2 = r2_score(target, pred)  \n",
        "# to compute adjusted R-squared\n",
        "    adjr2 = adj_r2_score(predictors, target, pred)  \n",
        "# to compute RMSE    \n",
        "    rmse = np.sqrt(mean_squared_error(target, pred)) \n",
        "# to compute MAE\n",
        "    mae = mean_absolute_error(target, pred)  \n",
        "# to compute MAPE\n",
        "    mape = mape_score(target, pred)  \n",
        "\n",
        "# creating a dataframe of the metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAE\": mae,\n",
        "            \"R-squared\": r2,\n",
        "            \"Adj. R-squared\": adjr2,\n",
        "            \"MAPE\": mape,\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ],
      "metadata": {
        "id": "GcTxcLmdvB5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the model performance on training set with 70% of the data\n",
        "print(\"Training Performance\\n\")\n",
        "olsres_train_perf = model_performance_regression(olsres, X_train, y_train)\n",
        "olsres_train_perf"
      ],
      "metadata": {
        "id": "IAIrjq6ivt32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the model performance on testing set with 30% of the data\n",
        "print(\"Test Performance\\n\")\n",
        "olsres_test_perf = model_performance_regression(olsres, X_test, y_test)\n",
        "olsres_test_perf"
      ],
      "metadata": {
        "id": "UhLNpH-rwJ-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Adjust R-squared for the training data is 84% and for the test data is 83%. This information lets us know that the model is not underfit. The training and test RSME and MAE are comparable so this further suggests that the model is not underfit. MAPE of 4.5 on the test data means that this model can predict within 4.5% of the normalized used price of a device.**"
      ],
      "metadata": {
        "id": "DwxL7PXUzSyH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9GxSQf-qH8e"
      },
      "source": [
        "## Checking Linear Regression Assumptions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In order to make statistical inferences from a linear regression model, it is important to ensure that the assumptions of linear regression are satisfied."
      ],
      "metadata": {
        "id": "UdGv3pQF50xP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naX-iXItqH-b"
      },
      "outputs": [],
      "source": [
        "#Testing for multicollinearity using VIF.\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "vif_series1 = pd.Series(\n",
        "    [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])],\n",
        "    index=X_train.columns,\n",
        ")\n",
        "print(\"VIF values: \\n\\n{}\\n\".format(vif_series1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When interpreting VIF:**\n",
        "\n",
        "-If VIF is 1 then there is no correlation between the predictor and the remaining predictor variables.\n",
        "-If VIF exceeds 5 or is close to exceeding 5, we say there is moderate multicollinearity.\n",
        "-If VIF is 10 or exceeding 10, it shows signs of high multicollinearity.\n",
        "\n",
        "**With the above knowledge we see that there are quite a few variables that show a moderate to high multi-collinearity. These values need to be treated.**"
      ],
      "metadata": {
        "id": "2LtEDxyO19O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing for multicollinearity using VIF.\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# we will define a function to check VIF\n",
        "def checking_vif(predictors):\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"feature\"] = predictors.columns\n",
        "\n",
        "    # calculating VIF for each feature\n",
        "    vif[\"VIF\"] = [\n",
        "        variance_inflation_factor(predictors.values, i)\n",
        "        for i in range(len(predictors.columns))\n",
        "    ]\n",
        "    return vif"
      ],
      "metadata": {
        "id": "Dbg17fSRUcJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treating_multicollinearity(predictors, target, high_vif_columns):\n",
        "    \"\"\"\n",
        "    Checking the effect of dropping the columns showing high multicollinearity\n",
        "    on model performance (adj. R-squared and RMSE)\n",
        "\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    high_vif_columns: columns having high VIF\n",
        "    \"\"\"\n",
        "# creating empty lists to store adj. R-squared and RMSE values\n",
        "    adj_r2 = []\n",
        "    rmse = []\n",
        "\n",
        "# building the ols models by dropping one of the high VIF columns at a time\n",
        "# storeing the adjusted R-squared and RMSE in the lists defined previously\n",
        "    for cols in high_vif_columns:\n",
        "# defining the new training set\n",
        "        train = predictors.loc[:, ~predictors.columns.str.startswith(cols)]\n",
        "\n",
        "# creating the model\n",
        "        olsmodel = sm.OLS(target, train).fit()\n",
        "\n",
        "# adding adj. R-squared and RMSE to the lists\n",
        "        adj_r2.append(olsmodel.rsquared_adj)\n",
        "        rmse.append(np.sqrt(olsmodel.mse_resid))\n",
        "# creating a dataframe for the results\n",
        "    temp = pd.DataFrame({\"col\": high_vif_columns,\n",
        "            \"Adj. R-squared after_dropping col\": adj_r2,\n",
        "            \"RMSE after dropping col\": rmse,}).sort_values(by=\"Adj. R-squared after_dropping col\", ascending=False)\n",
        "    temp.reset_index(drop=True, inplace=True)\n",
        "    return temp"
      ],
      "metadata": {
        "id": "QqL_XLC0UtJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing for multicollinearity using VIF.\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "vif_series1 = pd.Series(\n",
        "    [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])],\n",
        "    index=X_train.columns,\n",
        ")\n",
        "print(\"VIF values: \\n\\n{}\\n\".format(vif_series1))"
      ],
      "metadata": {
        "id": "xpQ0-oj_UyS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_list = [\"screen_size\", \"weight\",\"os_iOS\"]\n",
        "\n",
        "res = treating_multicollinearity(X_train, y_train, col_list)\n",
        "res"
      ],
      "metadata": {
        "id": "3YDoQztJVfQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Because we do not concern ourselves with the elevated VIF for dummy variables, we are looking at the other elevated VIF values. Dropping os_iOS does not change the Adj R-squared so I will drop that column from the dataframe and recheck VIF to see if the regression VIF.**"
      ],
      "metadata": {
        "id": "1BTt1MrsVXU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_to_drop = \"os_iOS\"\n",
        "X_train2 = X_train.loc[:, ~X_train.columns.str.startswith(col_to_drop)]\n",
        "X_test2 = X_test.loc[:, ~X_test.columns.str.startswith(col_to_drop)]"
      ],
      "metadata": {
        "id": "vcuMvCXHVZJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vif_series2 = pd.Series(\n",
        "    [variance_inflation_factor(X_train2.values, i) for i in range(X_train2.shape[1])],\n",
        "    index=X_train2.columns,\n",
        ")\n",
        "print(\"VIF values: \\n\\n{}\\n\".format(vif_series2))"
      ],
      "metadata": {
        "id": "MEzQP74OWUV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VIF are still high for screen size and weight but they affected the Adj R-squared so they will not be dropped.**"
      ],
      "metadata": {
        "id": "sBUVkgnsX4IX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropping high p-value variables**"
      ],
      "metadata": {
        "id": "IZ_yXmszYqag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dropping the predictor variables having a p-value greater than 0.05 is called for because they do not significantly impact the target variable.\n",
        "- We will not drop them all at once so we can monitor the change in the p-values change after drop.\n",
        "- To do this, we will build a loop that will check the p-values of the variables and drop the column with the highest p-value. Then it will create a new model without the dropped feature and check the p-values of the variables and drop the column with the highest p-value. The model will repeat these two steps till there are no columns with p-value > 0.05.\n"
      ],
      "metadata": {
        "id": "RMKVlZGmYu92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initial list of columns\n",
        "cols = X_train2.columns.tolist()\n",
        "\n",
        "# setting an initial max p-value\n",
        "max_p_value = 1\n",
        "\n",
        "while len(cols) > 0:\n",
        "    # defining the train set\n",
        "    x_train_aux = X_train2[cols]\n",
        "\n",
        "    # fitting the model\n",
        "    model = sm.OLS(y_train, x_train_aux).fit()\n",
        "\n",
        "    # getting the p-values and the maximum p-value\n",
        "    p_values = model.pvalues\n",
        "    max_p_value = max(p_values)\n",
        "\n",
        "    # name of the variable with maximum p-value\n",
        "    feature_with_p_max = p_values.idxmax()\n",
        "\n",
        "    if max_p_value > 0.05:\n",
        "        cols.remove(feature_with_p_max)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "selected_features = cols\n",
        "print(selected_features)"
      ],
      "metadata": {
        "id": "m0ejV7NcYoqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train3 = X_train2[selected_features] \n",
        "X_test3 = X_test2[selected_features] "
      ],
      "metadata": {
        "id": "bX1VIt3UZdCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rerunning the regression model after dropping all p-values greater than 1\n",
        "olsmodel2 = sm.OLS(y_train,X_train3).fit() \n",
        "print(olsmodel2.summary())"
      ],
      "metadata": {
        "id": "P-K6OKlnaA5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Adj R-squared has not changed when the p-values above 1 were dropped. This tells us that those variables did not affect the models performance or that these variables significantly impact the target variable.**"
      ],
      "metadata": {
        "id": "KUTTNWP8VXKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will continue to check the other assumptions using this model**"
      ],
      "metadata": {
        "id": "H985uwF7a8DB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST FOR LINEARITY AND INDEPENDENCE"
      ],
      "metadata": {
        "id": "xl6U7OEybSgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a dataframe with actual, fitted and residual values\n",
        "df_pred = pd.DataFrame()\n",
        "\n",
        "df_pred[\"Actual Values\"] = y_train  # actual values\n",
        "df_pred[\"Fitted Values\"] = olsmodel2.fittedvalues  # predicted values\n",
        "df_pred[\"Residuals\"] = olsmodel2.resid  # residuals\n",
        "\n",
        "df_pred.head()"
      ],
      "metadata": {
        "id": "yAIf61irbO1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #plotting the fitted values vs residuals\n",
        "\n",
        "sns.residplot(\n",
        "    data=df_pred, x=\"Fitted Values\", y=\"Residuals\", color=\"purple\", lowess=True\n",
        ")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Fitted vs Residual plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SWiYjYDZbeXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There is no real pattern to the fitted vs residual values. This supports the assumptions of linearity and independence.**"
      ],
      "metadata": {
        "id": "Ot8XQuvAb20A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# columns in training set\n",
        "X_train3.columns"
      ],
      "metadata": {
        "id": "IAT-ahtbqFKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of variables in training set with dependent variable\n",
        "sns.pairplot(df[[\"normalized_used_price\",'screen_size', 'main_camera_mp', 'selfie_camera_mp', 'ram','battery', 'weight', 'normalized_new_price', 'years_since_release']])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1zl3SbR6qJyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There appears to be a negative linear relationship between the normalized new price and normalized used price. We will transform this variable and rerun the regression.**"
      ],
      "metadata": {
        "id": "PFpTp8nH1kps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using square transformation\n",
        "X_train3[\"normalized_new_price_sq\"] = np.square(X_train3[\"normalized_new_price\"])\n",
        "\n",
        "# let's create a model with the transformed data\n",
        "olsmodel3 = sm.OLS(y_train, X_train3)\n",
        "olsmodel3 = olsmodel3.fit()\n",
        "print(olsmodel3.summary())"
      ],
      "metadata": {
        "id": "GO512BeStzKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let us recreate the dataframe with actual, fitted and residual values\n",
        "df_pred = pd.DataFrame()\n",
        "\n",
        "df_pred[\"Actual Values\"] = y_train.values.flatten()  # actual values\n",
        "df_pred[\"Fitted Values\"] = olsmodel3.fittedvalues.values  # predicted values\n",
        "df_pred[\"Residuals\"] = olsmodel3.resid.values  # residuals\n",
        "\n",
        "df_pred.head()"
      ],
      "metadata": {
        "id": "kqptPLSnvQ-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let us plot the fitted values vs residuals\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.residplot(\n",
        "    data=df_pred, x=\"Fitted Values\", y=\"Residuals\", color=\"purple\", lowess=True\n",
        ")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Fitted vs Residual plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ejHzca99vj0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By transforming the normalized new price and rerunning the regression, there is still no linear relationship between the residuals and the Adjusted R-squared increased slightly.**"
      ],
      "metadata": {
        "id": "PmPBXWLz3NB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST FOR NORMALITY"
      ],
      "metadata": {
        "id": "OIKf4-v3cLSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normality will be testing with the Q-Q plot of residuals and by using the Shapiro-Wilk test\n",
        "sns.histplot(data=df_pred, x='Residuals', kde=True)\n",
        "plt.title(\"Normality of eRsiduals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rx6NZgEicMKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The residuals almost have a bell shape that is slightly skewed to the left.**\n"
      ],
      "metadata": {
        "id": "BS4wsUlyc1vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the Q-Q plot for normal distribution of residuals\n",
        "import pylab\n",
        "import scipy.stats as stats\n",
        "\n",
        "stats.probplot(df_pred[\"Residuals\"], dist=\"norm\", plot=pylab) ## Complete the code check Q-Q plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mP2kiFYxdNdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The residuals almost follow a straight line except for the tails.**"
      ],
      "metadata": {
        "id": "P2jZrqK-da_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the Shapiro-Wilks Test\n",
        "#If the the p-value is greater than .05 the assumption is the that the residuals are normally distributed\n",
        "stats.shapiro(df_pred[\"Residuals\"])"
      ],
      "metadata": {
        "id": "hXkHev3zdkfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Because the Shapiro-Wilks p-value it is less than .05, we can say that the residuals are not normally distribution per this test. However, both the Q-Q and distribution plot indicate that the residuals are normally distributed. Per these results, the assumption is satisfied.**"
      ],
      "metadata": {
        "id": "H8Gr1ST8eVlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST FOR HOMOSCEDASTICITY"
      ],
      "metadata": {
        "id": "-X64aFL_fxc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the goldfeldquandt test, if we get a p-value greater than 0.05 the residuals are homoscedastic. Otherwise, they are heteroscedastic.\n",
        "import statsmodels.stats.api as sms\n",
        "from statsmodels.compat import lzip\n",
        "\n",
        "name = [\"F statistic\", \"p-value\"]\n",
        "test = sms.het_goldfeldquandt(df_pred[\"Residuals\"], X_train3)\n",
        "lzip(name, test)"
      ],
      "metadata": {
        "id": "WB7dj1QOfyYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since the p-value for the goldfeldquandt test is greater than .05, we can show that the residuals are homoscedastic.**"
      ],
      "metadata": {
        "id": "A7x1ioRtgGps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All of the assumptions of linear regression have been satified.**"
      ],
      "metadata": {
        "id": "RKRmn9BZgTm8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRYSDgFZMKtm"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_Sqvs4TMKtn"
      },
      "outputs": [],
      "source": [
        "print(olsmodel3.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the model parameters\n",
        "olsmodel3.params"
      ],
      "metadata": {
        "id": "TDafNzO4njpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us write the equation of linear regression\n",
        "Equation = \"mpg =\"\n",
        "print(Equation, end=\" \")\n",
        "for i in range(len(X_train3.columns)):\n",
        "    if i == 0:\n",
        "        print(olsmodel3.params[i], \"+\", end=\" \")\n",
        "    elif i != len(X_train3.columns) - 1:\n",
        "        print(\n",
        "            olsmodel3.params[i],\n",
        "            \"* (\",\n",
        "            X_train3.columns[i],\n",
        "            \")\",\n",
        "            \"+\",\n",
        "            end=\"  \",\n",
        "        )\n",
        "    else:\n",
        "        print(olsmodel3.params[i], \"* (\", X_train3.columns[i], \")\")"
      ],
      "metadata": {
        "id": "mRA8MgwLnvfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAKING PREDITIONS ON TEST DATA**"
      ],
      "metadata": {
        "id": "3s6ZcF_noIBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the training columns in the final model\n",
        "X_train3.columns"
      ],
      "metadata": {
        "id": "HXo-p1PNoC_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the test columns in the original data\n",
        "X_test.columns"
      ],
      "metadata": {
        "id": "Ymwuql8voK8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping columns from the test data that are not there in the training data\n",
        "X_test2 = X_test.drop(\n",
        "    ['int_memory','days_used','brand_name_Alcatel',\n",
        "       'brand_name_Apple', 'brand_name_Asus', 'brand_name_BlackBerry',\n",
        "       'brand_name_Celkon', 'brand_name_Coolpad', 'brand_name_Gionee',\n",
        "       'brand_name_Google', 'brand_name_HTC', 'brand_name_Honor',\n",
        "       'brand_name_Huawei', 'brand_name_Infinix', 'brand_name_Karbonn',\n",
        "       'brand_name_LG', 'brand_name_Lava','brand_name_Meizu', 'brand_name_Micromax', 'brand_name_Microsoft',\n",
        "       'brand_name_Motorola','brand_name_OnePlus',\n",
        "       'brand_name_Oppo', 'brand_name_Others', 'brand_name_Panasonic',\n",
        "       'brand_name_Realme', 'brand_name_Samsung', 'brand_name_Sony',\n",
        "       'brand_name_Spice', 'brand_name_Vivo', 'brand_name_XOLO','brand_name_ZTE','os_Windows',\n",
        "       'os_iOS','5g_yes' ], axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "9c6osyspoNne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming the weight column in the test data corresponding to the training set\n",
        "X_test2[\"normalized_new_price_sq\"] = np.square(X_test2[\"normalized_new_price\"])"
      ],
      "metadata": {
        "id": "VO2Vd6JPwbj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make predictions on the test set\n",
        "y_pred = olsmodel3.predict(X_test2)"
      ],
      "metadata": {
        "id": "TddrqOs4wkvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the RMSE on the train data\n",
        "rmse1 = np.sqrt(mean_squared_error(y_train, df_pred[\"Fitted Values\"]))\n",
        "rmse1"
      ],
      "metadata": {
        "id": "yfC5PhVbwvAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the RMSE on the test data\n",
        "rmse2 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "rmse2"
      ],
      "metadata": {
        "id": "JLquPrtow2Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The RMSE on the train and test data is comparable. So the model is not overfitted.**"
      ],
      "metadata": {
        "id": "W4KXLXsWxbbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the MAE on the train data\n",
        "mae1 = mean_absolute_error(y_train, df_pred[\"Fitted Values\"])\n",
        "mae1"
      ],
      "metadata": {
        "id": "m_wQ7UlLw5Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the MAE on the test data\n",
        "mae2 = mean_absolute_error(y_test, y_pred)\n",
        "mae2"
      ],
      "metadata": {
        "id": "ch9fkDu1w8dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The MAE on the training and test data indicate that predict the normalized used price within a mean error of .18 on the test data.**"
      ],
      "metadata": {
        "id": "XKgjtbK-xNRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**These factors make it seem that olsmodel3 is a good predictor of the factors contibuting to normalized used price.**"
      ],
      "metadata": {
        "id": "lMa4C3f_xk7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for use in insights\n",
        "olsmodel3.params"
      ],
      "metadata": {
        "id": "iHTrNtHSw_NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BkZh6eHluZK"
      },
      "source": [
        "## Actionable Insights and Recommendations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh_zkgqs4rqN"
      },
      "source": [
        "-A unit increase in the screen size of a device will increase the normalized used device price by .021 Euros.\n",
        "-A megapixal unit increase in the main camera will increase the normalized used device price by .017 Euros.\n",
        "- A megapixal unit increase in the selfie camera will increase the normalized used device price by .014 Euros.\n",
        "- A unit increase in RAM will increase the normalized used device price by .021 Euros.\n",
        "-A unit increase in the longevity of the battery will decrease the normalized used device price by .000016 Euros, indicating that there is not a big difference in price due to battery size.\n",
        "=The normalized new price of a comparable device has the biggest impact on the normalized used price. That amount is an increase of 1.04 Euros.\n",
        "-For every year that the device is older, there is a decreased in the normalized used price of .027 Euros.\n",
        "-Brand names do matter with Xiaomi being the most impactful with a .086 Euro increase in price. But there is an increase in price seen with Lenovo, Nokia and others as well.\n",
        "There is an increase in the normalized used price when the phone has 4g capability of .034 Euros.\n",
        "\n",
        "**The take aways from the data are:**\n",
        "- ReCell should focus on name brand phones that have the following features:\n",
        "    - A higher normalized new price for compariable devices.\n",
        "    - Brand name recognition\n",
        "    - 4g or higher capability\n",
        "    - Higher RAM and screen size\n",
        "    - Followed by the megapixal amount for both the main and selfie cameras.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/Apligian_ReCell_FullCode_Project_LearnerNotebook.ipynb"
      ],
      "metadata": {
        "id": "TYw0LfbR67R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SSRfAA2E8th8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWXXovuh4rqN"
      },
      "source": [
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3SntBY974rqJ",
        "v_-uuGqH-qTt",
        "xxhpZv9y-qTw",
        "UvpMDcaaMKtI",
        "__7ciGcIDPyk",
        "pVn5toJ7MKte",
        "KNzFis7eEaXj",
        "HeUzI1OB4rqM",
        "jvoU3F6oMKti",
        "a9GxSQf-qH8e",
        "jRYSDgFZMKtm",
        "2BkZh6eHluZK"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}